{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l6fbhWUuK3k"
   },
   "source": [
    "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Template para o Colab do Projeto Semestral**\n",
    "---\n",
    "\n",
    "Atenção, podem ser que nem todas as tarefas sejam executadas no Colab (a aplicação por exemplo, pode estar hospedada no streamlit cloud). Mas a maior parte pode estar aqui ou ao menos indicada e comentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lh0XUFpTuVp0"
   },
   "outputs": [],
   "source": [
    "#@title **Identificação do Grupo**\n",
    "\n",
    "#@markdown Integrantes do Grupo, nome completo em orgem alfabética (*informe \\<RA\\>,\\<nome\\>*)\n",
    "Aluno1 = '10409941, Carlos Eduardo Rosendo Basseto' #@param {type:\"string\"}\n",
    "Aluno2 = '10408953, Matheus Santiago de Brito ' #@param {type:\"string\"}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U25TbiNql6TC"
   },
   "source": [
    "# Detecção de discurso ofensivo em textos em português\n",
    "\n",
    "Este notebook implementa um fluxo completo de **Machine Learning** para detectar discurso ofensivo em comentários de texto, usando o dataset **OLID-BR**.\n",
    "\n",
    "Etapas principais:\n",
    "1. Carregamento e preparação do dataset `dougtrajano/olid-br` (Hugging Face).\n",
    "2. Criação de um arquivo CSV com as colunas `texto` e `label`.\n",
    "3. Separação em treino e teste.\n",
    "4. Balanceamento do conjunto de treino (undersampling da classe ofensiva).\n",
    "5. Treinamento e avaliação de três modelos:\n",
    "   - KNN\n",
    "   - Árvore de Decisão\n",
    "   - MLPClassifier (rede neural)\n",
    "6. Salvamento do modelo final para uso em uma aplicação Streamlit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yh6qOkHmB2E"
   },
   "source": [
    "## 1. Carregando o dataset OLID-BR\n",
    "\n",
    "Nesta célula, vamos:\n",
    "- Baixar o dataset `dougtrajano/olid-br` do Hugging Face;\n",
    "- Unir os conjuntos `train` e `test` em um único `DataFrame` do pandas;\n",
    "- Visualizar as colunas disponíveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515,
     "referenced_widgets": [
      "310af4d22a324d10ae73379b5191b76e",
      "052f9b27906e4c1db58c388d8981f7ed",
      "895746a830df4e22a3315bdcccbe081c",
      "8fbd6a65c610454cb40280f551931046",
      "556540d74e034f6c9c20210315759f94",
      "dbaa15279ee04e96b04fedcc95e977ee",
      "b618d34c807b403fb8a17b455f380780",
      "fd4446e04cb24e6793d5054cada48c01",
      "522641f1f53d48d099f2e04efdfdc6aa",
      "b903d740e33741f09be21993675f9ed1",
      "03e17cd25812444aa84d676f1401a0a2",
      "62277ed55f994c7f9e2571cb536e67ef",
      "939a73a2dcb54d6c83c6e6830b5274ab",
      "55da9e1d460e48f89609c75f423367e8",
      "d7c713efcf4b4768842bbe09081d3db3",
      "5286b84c07d04adf89725c4097eb9876",
      "8779bf126834468ea752deb9c9573987",
      "7ae68d52477c4f57940dabd79906f3e0",
      "dd8b81aa205e43d89c43d8b962b65f07",
      "4eef4a54516f4ec7b9bb38c3d16dd32b",
      "335abda02878469d9a527cba51515eee",
      "aa9b561b498240bd831ee8b1acf4933e",
      "442d192ed6db4440bc1959b4d05aa750",
      "05aed0e700be40cea5c94ab372599902",
      "9e1b4dab569b4c7f9f53c09abb76a4cd",
      "9e2863a094ad4dc6a477fb42c463104a",
      "db0bf009b42648599f5bc169e4c94b37",
      "efcea23255924c268de8f39704e259e9",
      "be0f1bba09dc459bbfae36459294aebc",
      "f3502a52bd0942dba95a143bb7527a27",
      "05e6f05947654483bfbe119a3806921c",
      "a35561155a244a06b9c6c59b4e52dee1",
      "ddc2a380f3d9411e839f0b5ee631e65d",
      "11010d225d4b4c9bb8028dc4420ac56a",
      "2f16ac0b881749a6ac9e931283bd8044",
      "689635057c594320928ab8f6693a421a",
      "8fe26a5529b148308000228868fac64f",
      "e0a7436a78464ed28946d14ceb51d09d",
      "20bcdb14eaf1472abfe82439bbae2a01",
      "4e381f31cf70479e860d376dd9422c76",
      "c5dc1c3f01b443289a4601bc04452a9a",
      "d4ec4f7bf6d242e39f56ff1363a8349f",
      "9569171370ae420eb3e200f61494120a",
      "368f829bfb7841fa9dfae8df8ae4f723",
      "ed166805b1de4884b2642441d637d5cd",
      "cb2d56a2253145cf8d3fdc71ddb154e3",
      "8aa82ee7a34d4957bc96fe090595ad9f",
      "65130a742e6a4906aa054e6e06757c59",
      "77b2d7d9499842688a3171bbc091ade5",
      "b1045d8b95344cc0ba3f1652d308006a",
      "34c0cb58421d4c4da22cfbf15003d75b",
      "8c848f90c01e49c9a9a95cb8f73840ad",
      "27794edcab3a4d45b0862d6a72612889",
      "77392784e1e84b79b7f7fa7e8eb7c86e",
      "7b562462894b4321a92ca1323560bf78",
      "872f21fb74864f4fa9af4b4a6b5ada8b",
      "7a6f8e50145d47c9bdfffe5f567e7e25",
      "64c4b7e054fd408d8605211489e40d61",
      "72822365c7ac4a6b95e871fffabe0dcc",
      "04cf7ce4d78d41f38b1ef803c14aaf6b",
      "70e335a409b94c88beedba026a5675d1",
      "2ee50e3b49764273bacfa4e541f5c8ad",
      "47ffeac306b34f02b0a41a901f16fb4e",
      "6b81de1de7354c73980b8193870ea0c6",
      "fdf23ff4008a4e32b225124106a1142e",
      "9eb510ab309948769b179ce3cc79c7a5"
     ]
    },
    "id": "ZhZjyH6WWz_x",
    "outputId": "d4f1cc58-3978-4a15-de84-84f50439fda2"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Carregar dataset OLID-BR\n",
    "dataset_id = \"dougtrajano/olid-br\"\n",
    "ds = load_dataset(dataset_id)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "86Nlzla7XHIB",
    "outputId": "0e409042-7da2-4c34-e2bc-098f10ebf23a"
   },
   "outputs": [],
   "source": [
    "df_train = ds[\"train\"].to_pandas()\n",
    "df_test  = ds[\"test\"].to_pandas()\n",
    "\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "print(\"Colunas disponíveis:\")\n",
    "print(df.columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyoVhbTHmFbj"
   },
   "source": [
    "## 2. Selecionando colunas relevantes e criando a coluna `label`\n",
    "\n",
    "Aqui vamos:\n",
    "- Manter apenas as colunas `text` (comentário) e `is_offensive` (rótulo original);\n",
    "- Renomear `text` para `texto`;\n",
    "- Transformar `is_offensive` em uma coluna numérica `label`, onde:\n",
    "  - `1` = ofensivo (`OFF`)\n",
    "  - `0` = não ofensivo (`NOT`);\n",
    "- Ver a distribuição das classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "65g4ukjGXXjX",
    "outputId": "87ec7a74-b8cd-496c-8c0f-8d4b37fc80df"
   },
   "outputs": [],
   "source": [
    "# Vamos usar apenas o texto e a info se é ofensivo ou não\n",
    "df = df[[\"text\", \"is_offensive\"]].copy()\n",
    "\n",
    "# Renomear coluna de texto para o padrão do projeto\n",
    "df = df.rename(columns={\"text\": \"texto\"})\n",
    "\n",
    "# Mapear OFF/NOT para 1/0\n",
    "def map_offensive(x):\n",
    "    return 1 if x == \"OFF\" else 0\n",
    "\n",
    "df[\"label\"] = df[\"is_offensive\"].apply(map_offensive)\n",
    "\n",
    "print(\"Distribuição das classes (label):\")\n",
    "print(df[\"label\"].value_counts())\n",
    "print(df[\"label\"].value_counts(normalize=True))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiQHyb0KmjLb"
   },
   "source": [
    "## 3. Salvando o dataset preparado em CSV\n",
    "\n",
    "Agora salvamos o DataFrame em um arquivo CSV que será usado nas próximas etapas do projeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiKau1dxXfGS",
    "outputId": "026d0e38-b7b3-4ac0-8fbf-b21d3f31f7b6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "caminho_csv = \"../data/dados_hatespeech.csv\"\n",
    "df.to_csv(caminho_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"CSV salvo em:\", caminho_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3aW4849mmSJ"
   },
   "source": [
    "## 4. Importando bibliotecas de modelagem e carregando o CSV\n",
    "\n",
    "Nesta célula:\n",
    "- Importamos as bibliotecas necessárias para treinamento e avaliação dos modelos;\n",
    "- Carregamos o arquivo CSV gerado na etapa anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "v7Bf23_WYLrf",
    "outputId": "c122a82e-5185-4fb4-d9f9-f7f804b3a196"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Modelos que vamos testar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Carregar o CSV que você salvou\n",
    "caminho_csv = \"/data/dados_hatespeech.csv\"\n",
    "df = pd.read_csv(caminho_csv)\n",
    "\n",
    "print(\"Primeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7InEyEam4AC"
   },
   "source": [
    "## 5. Separando conjunto de treino e teste\n",
    "\n",
    "Aqui separamos:\n",
    "- `X` = textos (`texto`)\n",
    "- `y` = rótulos (`label`)\n",
    "\n",
    "Usamos `train_test_split` para criar:\n",
    "- 80% para treino\n",
    "- 20% para teste\n",
    "\n",
    "mantendo a proporção original das classes (parâmetro `stratify`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpm4yPhkY79U",
    "outputId": "3d07ba18-d3a8-45cd-e933-b77b5767fd5d"
   },
   "outputs": [],
   "source": [
    "# Separar features e rótulos\n",
    "X = df[\"texto\"].astype(str)\n",
    "y = df[\"label\"].astype(int)\n",
    "\n",
    "# Separar em treino/teste (80% / 20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y   # mantém proporção das classes\n",
    ")\n",
    "\n",
    "print(\"Tamanho do treino:\", len(X_train))\n",
    "print(\"Tamanho do teste :\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUi0bvr8m7gN"
   },
   "source": [
    "## 6. Balanceando o conjunto de treino (undersampling)\n",
    "\n",
    "O dataset original tem muito mais exemplos ofensivos do que não ofensivos.\n",
    "Nesta célula:\n",
    "- Criamos um DataFrame com `X_train` e `y_train`;\n",
    "- Contamos a distribuição original;\n",
    "- Fazemos **undersampling** da classe ofensiva para ter o mesmo número de exemplos que a classe não ofensiva;\n",
    "- Embaralhamos os dados e atualizamos `X_train` e `y_train` com a versão balanceada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYpRnDOYfGn4",
    "outputId": "da57cc92-3afe-4243-bccd-b9c03618e2fa"
   },
   "outputs": [],
   "source": [
    "# Juntar X_train e y_train em um DataFrame\n",
    "train_df = pd.DataFrame({\n",
    "    \"texto\": X_train,\n",
    "    \"label\": y_train\n",
    "})\n",
    "\n",
    "print(\"Distribuição original no treino:\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "\n",
    "# Separar por classe\n",
    "train_normal = train_df[train_df[\"label\"] == 0]\n",
    "train_ofensivo = train_df[train_df[\"label\"] == 1]\n",
    "\n",
    "# Fazer undersampling da classe ofensiva para ter o mesmo número de exemplos que a classe normal\n",
    "train_ofensivo_down = train_ofensivo.sample(\n",
    "    n=len(train_normal),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Juntar e embaralhar\n",
    "train_bal = pd.concat([train_normal, train_ofensivo_down]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"\\nDistribuição balanceada no treino:\")\n",
    "print(train_bal[\"label\"].value_counts())\n",
    "\n",
    "# Atualizar X_train e y_train para usar o conjunto balanceado\n",
    "X_train = train_bal[\"texto\"]\n",
    "y_train = train_bal[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gilpiLuXm_AU"
   },
   "source": [
    "## 7. Função para treinar e avaliar modelos\n",
    "\n",
    "Para evitar repetição de código, criamos a função `treinar_e_avaliar`, que:\n",
    "- Monta um `Pipeline` com `TfidfVectorizer` + modelo;\n",
    "- Treina o modelo no conjunto de treino;\n",
    "- Avalia no conjunto de teste;\n",
    "- Imprime acurácia e relatório de classificação;\n",
    "- Mostra a matriz de confusão;\n",
    "- Retorna o pipeline treinado e um dicionário com métricas (acurácia e F1 da classe ofensiva).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHumJ8dyZKdU"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def treinar_e_avaliar(nome_modelo, modelo_base):\n",
    "    \"\"\"\n",
    "    nome_modelo: Apenas para exibição\n",
    "    modelo_base: O estimador (KNN, Árvore, MLP etc.)\n",
    "    \"\"\"\n",
    "    print(f\"\\n================ {nome_modelo} ================\\n\")\n",
    "\n",
    "    # Pipeline: TF-IDF + modelo\n",
    "    pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            ngram_range=(1, 2),      # unigram + bigram\n",
    "            max_features=20000       # limita tamanho do vocabulário\n",
    "        )),\n",
    "        (\"clf\", modelo_base)\n",
    "    ])\n",
    "\n",
    "    # Treinar\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predizer\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Acurácia\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Acurácia: {acc:.4f}\\n\")\n",
    "\n",
    "    # Relatório completo\n",
    "    print(\"Relatório de classificação:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Normal\", \"Ofensivo\"],\n",
    "        yticklabels=[\"Normal\", \"Ofensivo\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predito\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(f\"Matriz de Confusão - {nome_modelo}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # F1-score da classe OFENSIVO (1)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1_classe_1 = report[\"1\"][\"f1-score\"]\n",
    "\n",
    "    return pipeline, {\n",
    "        \"nome\": nome_modelo,\n",
    "        \"acuracia\": acc,\n",
    "        \"f1_ofensivo\": f1_classe_1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZLq4TyvnGb1"
   },
   "source": [
    "## 8. Treinando e avaliando o modelo KNN\n",
    "\n",
    "Primeiro modelo: **KNN (k=5)**.\n",
    "\n",
    "Aqui chamamos a função `treinar_e_avaliar` passando o KNN como estimador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "M7VN5qm3Znwa",
    "outputId": "ef3d9248-8ddc-46ed-e8aa-6ec51d533fc0"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Modelo KNN com k = 5 vizinhos\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "modelo_knn, resultados_knn = treinar_e_avaliar(\"KNN (k=5)\", knn)\n",
    "\n",
    "print(\"\\nResultados KNN:\", resultados_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV9EpYQlnLuk"
   },
   "source": [
    "## 9. Treinando e avaliando o modelo Árvore de Decisão\n",
    "\n",
    "Agora treinamos uma **Árvore de Decisão** com profundidade máxima limitada para tentar evitar overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "_kBymYQBZ3qH",
    "outputId": "20d763f5-0bf3-4ce6-a764-bfec9d90cc5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Árvore com profundidade máxima para evitar overfitting\n",
    "tree = DecisionTreeClassifier(\n",
    "    max_depth=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "modelo_tree, resultados_tree = treinar_e_avaliar(\"Árvore de Decisão (max_depth=20)\", tree)\n",
    "\n",
    "print(\"\\nResultados Árvore:\", resultados_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UNB2BOKnOEp"
   },
   "source": [
    "## 10. Treinando e avaliando o modelo MLPClassifier (rede neural)\n",
    "\n",
    "Por fim, treinamos uma rede neural simples (`MLPClassifier`) com duas camadas ocultas.\n",
    "Este foi o modelo que apresentou melhor desempenho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "aD9ynykcaCVB",
    "outputId": "afe001a1-5f9e-4a52-93d4-c1af5ec3fb10"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Rede MLP com 2 camadas ocultas\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    max_iter=10,  # poucas iterações por causa do custo\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "modelo_mlp, resultados_mlp = treinar_e_avaliar(\"MLPClassifier (64,32)\", mlp)\n",
    "\n",
    "print(\"\\nResultados MLP:\", resultados_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz1pkudwnRa1"
   },
   "source": [
    "## 11. Salvando o modelo final para uso no Streamlit\n",
    "\n",
    "Aqui salvamos o `pipeline` treinado (TF-IDF + MLP) em um arquivo `.pkl`,\n",
    "que será carregado pela aplicação Streamlit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYC1OZUTakDx",
    "outputId": "40e85ef3-8edb-410a-92f8-ce5b0fe6e218"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Criar pasta models (se ainda não existir)\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "# Caminho do arquivo do modelo\n",
    "caminho_modelo = \"./models/modelo_hatespeech_mlp.pkl\"\n",
    "\n",
    "# Salvar o pipeline inteiro (TF-IDF + MLP)\n",
    "joblib.dump(modelo_mlp, caminho_modelo)\n",
    "\n",
    "print(\"Modelo salvo em:\", caminho_modelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-z-hdwsup8E"
   },
   "source": [
    "# **Referências**\n",
    "\n",
    "1. Dataset OLID-BR\n",
    "Trajano, D. (2022). OLID-BR: Offensive Language Identification Dataset in Brazilian Portuguese. Disponível em:\n",
    "https://huggingface.co/datasets/dougtrajano/olid-br\n",
    "\n",
    "2. TF-IDF — Vetorização de Texto\n",
    "Ramos, J. (2003). Using TF-IDF to Determine Word Relevance in Document Queries. Proceedings of the First Instructional Conference on Machine Learning.\n",
    "\n",
    "3. Scikit-Learn — Modelos de Machine Learning\n",
    "Pedregosa, F. et al. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research.\n",
    "https://scikit-learn.org/\n",
    "\n",
    "4. Streamlit — Interface da Aplicação\n",
    "Streamlit Documentation.\n",
    "https://docs.streamlit.io/\n",
    "\n",
    "5. Catálogo de dados de discurso de ódio\n",
    "Vidgen, B., & Derczynski, L. (2020). Datasets for abusive language detection. PLoS ONE.\n",
    "https://hatespeechdata.com"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
